{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data =  open('links.txt').read().splitlines()\n",
    "PATH = 'data/'\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(PATH + path) for path in data]\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['DATETIME'] = pd.to_datetime(df.DATE + \" \" + df.TIME, format='%m/%d/%Y %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure there are no duplicate entries\n",
    "df.drop_duplicates(subset=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATETIME\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[[\"PREV_DATETIME\", \"PREV_ENTRIES\", \"PREV_EXITS\"]] = (df.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATETIME\", \"ENTRIES\", \"EXITS\"]\n",
    "                                            .transform(lambda grp: grp.shift(1)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"PREV_DATETIME\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['TIME_INTERVAL'] = df['DATETIME'] - df['PREV_DATETIME']\n",
    "df = df.drop(df[(df['TIME_INTERVAL'] > '05:00:00') & (df['TIME_INTERVAL'] < '03:00:00')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify entry counts that are negative and remove the ones with outrageous values\n",
    "df['ENTRY_COUNT'] = df.ENTRIES - df.PREV_ENTRIES\n",
    "df.ix[df.ENTRY_COUNT < 0, 'ENTRY_COUNT'] =  - df['ENTRY_COUNT']\n",
    "df = df.drop(df[df.ENTRY_COUNT > 1000000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify exit counts that are negative and remove the ones with outrageous values\n",
    "df['EXIT_COUNT'] = df.EXITS - df.PREV_EXITS\n",
    "df.ix[df.EXIT_COUNT < 0, 'EXIT_COUNT'] =  - df['EXIT_COUNT']\n",
    "df = df.drop(df[df.EXIT_COUNT > 1000000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE'], format='%m/%d/%Y')\n",
    "df['WEEKDAY'] = df['DATE'].dt.dayofweek\n",
    "df['TIME'] = pd.to_datetime(df['TIME'], format='%H:%M:%S')\n",
    "df['HOUR'] = df['TIME'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[(df['DATE'] >= '05/01/2016') & (df['DATE'] < '07/01/2016')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# Merges same station\n",
    "df['COMPLETE_NAME'] = df['STATION'] + ' ' + df['LINENAME']\n",
    "with open('name_mapping.csv') as namefile:\n",
    "    reader = csv.reader(namefile)\n",
    "    for row in reader:\n",
    "        df.loc[df.COMPLETE_NAME == row[0], 'COMPLETE_NAME'] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final info on median income and percentage of tech people\n",
    "df_income = pd.read_csv('final_merge_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.merge(df, df_income, on=['COMPLETE_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# divides data to 2 dfs\n",
    "df_weekday = final_df[(final_df.WEEKDAY < 3 )|(final_df.WEEKDAY > 4)]\n",
    "df_weekend = final_df[(final_df.WEEKDAY > 2 )&(final_df.WEEKDAY < 5 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# divides by 100 because value is in percentage\n",
    "df_weekend.loc['Information_Industry_%'] = df_weekend['Information_Industry_%'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get entry data based on percentage of tech people\n",
    "df_weekend['ENTRY_TECH_%'] = df_weekend['ENTRY_COUNT'] * df_weekend['Information_Industry_%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sum up entry counts daily, and take the average\n",
    "df_weekend_daily_entries = df_weekend.groupby(['COMPLETE_NAME', 'DATE'], as_index=False)['ENTRY_COUNT','ENTRY_TECH_%'].sum()\n",
    "df_weekend_daily_entries = df_weekend_daily_entries.groupby(['COMPLETE_NAME'], as_index=False)['ENTRY_COUNT', 'ENTRY_TECH_%'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_weekend_top = df_weekend_daily_entries.sort_values(by=['ENTRY_TECH_%'], ascending=False).head(20)\n",
    "\n",
    "sns.barplot(x='COMPLETE_NAME', y='ENTRY_TECH_%', data=df_weekend_top)\n",
    "ax = plt.axes()\n",
    "ax.set_title('Top stations on the weekends with people in the tech industry')\n",
    "ax.set_ylabel('Daily entries')\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_weekday_morning = df_weekday[(df_weekday.HOUR > 6) & (df_weekday.HOUR < 13)]\n",
    "df_weekday_morning = df_weekday_morning.groupby(['COMPLETE_NAME', 'DATE'], as_index=False)['ENTRY_COUNT', 'EXIT_COUNT'].sum()\n",
    "df_weekday_morning = df_weekday_morning.groupby(['COMPLETE_NAME'], as_index=False).mean()\n",
    "df_weekday_morning['EXIT_ENTRY_RATIO'] = df_weekday_morning['EXIT_COUNT'] / df_weekday_morning['ENTRY_COUNT']\n",
    "\n",
    "mask = ((df_weekday_morning['EXIT_COUNT'] < 20000) & (df_weekday_morning['EXIT_ENTRY_RATIO'] < 10)\n",
    "        & (df_weekday_morning['EXIT_COUNT'] > 5000) & (df_weekday_morning['EXIT_ENTRY_RATIO']> 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_weekend_fave = pd.merge(df_weekday_morning,df_weekend, on=['COMPLETE_NAME'])\n",
    "df_weekend_fave.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = ((df_weekend_fave['ENTRY_TECH_%'] <40000) & (df_weekend_fave['ENTRY_EXIT_RATIO'] < 20)\n",
    "        & (df_weekend_fave['ENTRY_TECH_%'] >10000) & (df_weekend_fave['ENTRY_EXIT_RATIO'] > 2))\n",
    "g = sns.lmplot('ENTRY_EXIT_RATIO', 'ENTRY_TECH_%', \n",
    "           data=df_weekend_fave[mask], \n",
    "           fit_reg=False,   \n",
    "           scatter_kws={\"marker\": \"D\", \n",
    "                        \"s\": 10},\n",
    "           hue='COMPLETE_NAME',\n",
    "          )\n",
    "g.set_axis_labels(\"Entry:Exit\", \"Entry Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = len(df_weekend_fave)\n",
    "df_weekend_fave['ratio_quantile'] = df_weekend_fave['ENTRY_EXIT_RATIO'].rank() / length\n",
    "df_weekend_fave['tech_quantile'] = df_weekend_fave['ENTRY_TECH_%'].rank() / length\n",
    "df_weekend_fave.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_weekend_fave['total_score'] = df_weekend_fave['ratio_quantile'] + df_weekend_fave['tech_quantile']\n",
    "df_weekend_fave.sort_values(by=['tech_quantile'], ascending=False).head(5)['COMPLETE_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_residential['COMPLETE_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_residential = pd.merge(df_residential, df_weekend, how='left')\n",
    "df_residential = df_weekend.mask(df_weekend['COMPLETE_NAME'].isin(df_residential.STATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_residential_top_times = df_residential.groupby(['WEEKDAY', 'HOUR'], as_index=False)['ENTRY_COUNT'].mean()\n",
    "\n",
    "df_saturday = df_residential_top_times[df_residential_top_times.WEEKDAY == 3]\n",
    "df_sunday = df_residential_top_times[df_residential_top_times.WEEKDAY == 4]\n",
    "sns.barplot(x='HOUR', y='ENTRY_COUNT', data=df_saturday)\n",
    "ax = plt.axes()\n",
    "ax.set_title('Entry count on Saturday in Residential Areas')\n",
    "ax.set_ylabel('Entry Count')\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(90)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
